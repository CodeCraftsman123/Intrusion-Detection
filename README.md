# ğŸš€ Intrusion Detection using Machine Learning

Welcome to the **Intrusion Detection Project**! This project uses various machine learning algorithms like Random Forest, SVM, and XGBoost to detect anomalies in a network traffic dataset. By reducing the dataset size and focusing on key features, we aim to build efficient models that can classify traffic as "normal" or "anomaly."

---

## ğŸ“‚ Project Overview

The objective of this project is to:

- ğŸ“Š Build models to classify network traffic as **normal** or **anomaly**.
- ğŸ§  Use feature selection with **Mean Decrease Gini Impurity** to focus on the most important features.
- âš™ï¸ Train models using **Random Forest**, **SVM (Radial Kernel)**, and **XGBoost**, comparing their performance using accuracy, precision, recall, and more.

---

## ğŸ“ Files and Structure

| **File**                      | **Description** |
|-------------------------------|-----------------|
| `KDDTrain.csv`                 | The original dataset containing labeled network traffic records. |
| `15kpointsofeachclassfinal.csv`| A reduced dataset with 15,000 points per class ("normal" and "anomaly"). |
| `50kpointsofeachclassfinal.csv`| A larger version of the reduced dataset with 50,000 points per class. |

---

## âš™ï¸ Code Breakdown

### 1. ğŸ“ `MakingCSVFileWithLessDataPoints.R`

This script reduces the dataset size by selecting 15,000 records from both the "normal" and "anomaly" classes:

- **Input**: `KDDTrain.csv`.
- **Output**: A shuffled dataset saved as `15kpointsofeachclassfinal.csv`.

### 2. ğŸŒŸ `MeanDecreaseGiniImpurityFeatureSelection.R`

This script ranks the features using a Random Forest model based on **Mean Decrease Gini Impurity**:

- **Input**: `15kpointsofeachclassfinal.csv`.
- **Process**: 
  - Feature selection to focus on the most relevant features.
  - Creation of multiple datasets with the top 10, 15, 20, etc., features.
- **Output**: Datasets with reduced feature sets.

### 3. ğŸ’» `AllalgoCP.R`

This script compares three machine learning algorithmsâ€”Random Forest, SVM, and XGBoost:

- **Random Forest**: Trained using cross-validation and fine-tuned `mtry` values.
- **SVM**: Trained with a **Radial Kernel**.
- **XGBoost**: Trained with hyperparameter tuning using cross-validation.
  
- **Metrics**: 
  - **Accuracy** ğŸ¯
  - **Precision** âœ…
  - **Recall** ğŸ”
  - **F1-Score** âš–ï¸
  - **Specificity** ğŸ”‘

## ğŸ“Š Results

After performing feature selection and training the models, we evaluated their performance on the test dataset. The evalution of each model is present in the pdf `Intrusion Detection.pdf`

---

## ğŸ›  Setup Instructions

### Install the Required Libraries

Run the following commands to install the necessary R packages:

```r
install.packages(c("randomForest", "caret", "kernlab", "xgboost"))
